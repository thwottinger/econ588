{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model to illustrate Elastic Net via the Monte Carlo Method is a multiple regression with dependent variable y, independent variables comprising x, unknown parameters comprising $\\beta$, and an error term $\\varepsilon$<br />\n",
    "$y_i=x_i'\\beta+\\varepsilon_i$ <br />\n",
    "For the purposes of Monte Carlo simulation, values for y will be calculated using known parameters of $\\beta$ that are as follows: <br />\n",
    "$\\beta = (10, 10, 5, 5, 1, ._{98}., 1, 0, ._{394}., 0)^T$ <br />\n",
    "The number of predictors and number of observations are as follows: <br />\n",
    "$p = 500$ <br />\n",
    "$n = 200$ <br />\n",
    "Predictors will be correlated as follows: <br />\n",
    "$Cov(X)_{ij} = (0.7)^{|i-j|}$ <br />\n",
    "The means of the multivariate normal distribution from which X will be sampled are all 0. The error term follows a normal distribution with a mean of 0 and a variance of 1.\n",
    "This model provides a series of problems for normal (OLS) estimation. First, the number of predictors is greater than the number of observations, so OLS can't proceed without losing some of the predictors. Second, the number of predictors will still be high if OLS removes predictors until it can function, and many of those predictors have no effect on y. Third, the predictors are correlated with each-other. <br />\n",
    "To solve these problems, LASSO can do variable selection to reduce the problems involved with a high number of noisy predictors, and Ridge can reduce the penalties of multicollinearity with variable shrinkage. Elastic Net allows us to gain some of the advantages of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "numpy.random.seed(12)\n",
    "def xxCov(a, b):\n",
    "    return math.pow(0.7, abs(a-b))\n",
    "n = 200\n",
    "p = 500\n",
    "A = range(1, p + 1)\n",
    "B = range(1, p + 1)\n",
    "r = numpy.zeros((len(A),len(B)))\n",
    "for i in range(len(A)):\n",
    "    for j in range(len(B)):\n",
    "        r[i,j] = xxCov(A[i], B[j])\n",
    "\n",
    "beta = [10, 10, 5, 5]\n",
    "beta.extend(numpy.ones(100))\n",
    "beta.extend(numpy.zeros(p - len(beta)))\n",
    "runs = 100\n",
    "\n",
    "mseEl = []\n",
    "mseReg = []\n",
    "bCoefs = []\n",
    "lambdas = [.9, 1]\n",
    "for i in range(0, runs):\n",
    "    x = numpy.random.multivariate_normal([0] * p, r, n)\n",
    "    y = []\n",
    "    for j in range(0, n):\n",
    "        y.append(sum([a*b for a,b in zip(beta,x[j])]) + sum(numpy.random.normal(0, 1, 1)))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)    \n",
    "    mseElParts = []\n",
    "    bParts = []\n",
    "    \n",
    "    reg = ElasticNetCV(alphas=numpy.arange(0.01, 0.1, 0.01), cv=5, fit_intercept=True, l1_ratio=0)\n",
    "    reg.fit(x_train, y_train)\n",
    "    mseElParts.append(numpy.mean((y_test - reg.predict(x_test)) ** 2))\n",
    "    bParts.append(reg.coef_)\n",
    "    \n",
    "    for j in lambdas:\n",
    "        reg = ElasticNetCV(cv=5, fit_intercept=True, l1_ratio=j)\n",
    "        reg.fit(x_train, y_train)\n",
    "        mseElParts.append(numpy.mean((y_test - reg.predict(x_test)) ** 2))\n",
    "        bParts.append(reg.coef_)\n",
    "        \n",
    "        \n",
    "    mseEl.append(mseElParts)\n",
    "    x_train = sm.add_constant(x_train)\n",
    "    x_test = sm.add_constant(x_test)\n",
    "    ols = sm.OLS(y_train, x_train)\n",
    "    results = ols.fit()\n",
    "    bParts.append(results.params)\n",
    "    bCoefs.append(bParts)\n",
    "    mseReg.append(numpy.mean((y_test - results.predict(x_test)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and Standard Deviation for MSE of Ridge Regression\n",
      "Mean: 221.92111811129854 Standard Deviation: 53.7774189042728 \n",
      "\n",
      "Mean and Standard Deviation for MSE of Elastic Net with lambda of 0.9\n",
      "Mean: 26.836244126281716 Standard Deviation: 10.518996635510035 \n",
      "\n",
      "Mean and Standard Deviation for MSE of LASSO Regression\n",
      "Mean: 31.979416753952087 Standard Deviation: 11.289221942052153 \n",
      "\n",
      "Mean and Standard Deviation for MSE of OLS\n",
      "Mean: 223.25917909821635 Standard Deviation: 52.427523700104466\n"
     ]
    }
   ],
   "source": [
    "print \"Mean and Standard Deviation for MSE of Ridge Regression\"\n",
    "print \"Mean:\", numpy.mean([item[0] for item in mseEl]), \"Standard Deviation:\", numpy.std([item[0] for item in mseEl]), \"\\n\"\n",
    "for i in range(0, len(lambdas) - 1):\n",
    "    print \"Mean and Standard Deviation for MSE of Elastic Net with lambda of\", lambdas[i]\n",
    "    print \"Mean:\", numpy.mean([item[i + 1] for item in mseEl]), \"Standard Deviation:\", numpy.std([item[i + 1] for item in mseEl]), \"\\n\"\n",
    "print \"Mean and Standard Deviation for MSE of LASSO Regression\"\n",
    "print \"Mean:\", numpy.mean([item[len(lambdas)] for item in mseEl]), \"Standard Deviation:\", numpy.std([item[len(lambdas)] for item in mseEl]), \"\\n\"\n",
    "print \"Mean and Standard Deviation for MSE of OLS\"\n",
    "print \"Mean:\", numpy.mean(mseReg), \"Standard Deviation:\", numpy.std(mseReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net's mean of coefficients across 100 runs differs less absolutely from the true beta value for 275 coefficients out of 500. LASSO's averages are only better for 225 coefficients.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.hist([item[len(lambdas)] for item in mseEl])\n",
    "#plt.show()\n",
    "countElastic = 0\n",
    "countLASSO = 0\n",
    "for i in range(0, p):\n",
    "    if abs(numpy.mean([item[1][i] for item in bCoefs]) - beta[i]) > abs(numpy.mean([item[2][i] for item in bCoefs]) - beta[i]):\n",
    "        countLASSO = countLASSO + 1\n",
    "    else:\n",
    "        countElastic = countElastic + 1\n",
    "\n",
    "print \"Elastic Net's mean of coefficients across\", runs, \"runs differs less absolutely from the true beta value for\", countElastic, \"coefficients out of\", str(p) + \". LASSO's averages are only better for\", countLASSO, \"coefficients.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
